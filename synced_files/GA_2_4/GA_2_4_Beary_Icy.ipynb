{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GA 2.4: Beary Icy\n",
    "\n",
    "<h1 style=\"position: absolute; display: flex; flex-grow: 0; flex-shrink: 0; flex-direction: row-reverse; top: 60px;right: 30px; margin: 0; border: 0\">\n",
    "    <style>\n",
    "        .markdown {width:100%; position: relative}\n",
    "        article { position: relative }\n",
    "    </style>\n",
    "    <img src=\"https://gitlab.tudelft.nl/mude/public/-/raw/main/tu-logo/TU_P1_full-color.png\" style=\"width:100px\" />\n",
    "    <img src=\"https://gitlab.tudelft.nl/mude/public/-/raw/main/mude-logo/MUDE_Logo-small.png\" style=\"width:100px\" />\n",
    "</h1>\n",
    "<h2 style=\"height: 10px\">\n",
    "</h2>\n",
    "\n",
    "*[CEGM1000 MUDE](http://mude.citg.tudelft.nl/): Week 2.4, Time Series Analysis. For: December 6, 2024*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Winter is coming and it is time to start getting our models ready for the ice classic. Our first goal is to improve the temperature model, as that seems to be an important factor in determining breakup day. Temperature is notoriously hard to predict, but we can analyze historical data to get a better understanding of the patterns.\n",
    "\n",
    "In this assignment we will analyze a time series from a **single year**; in fact, only the **first 152 days of the year**, from January 1 until June 1. This is the period of interest for the ice classic, as the ice forms in this period, reaching its maximum thickness between January-March, and then starts melting, with breakup day typically happening in April or May.\n",
    "\n",
    "Remember that we have until April 5 to place a bet. Why, then do we want to fit a model several months beyond this point? This gives us confidence in assessing the ability of the model to predict temperature, so that when we use it on April 5 to make **predictions** about the future, we can understand the uncertainty associated with it.\n",
    "\n",
    "Let's start by loading the data and plotting it, then we will determine which components should be used to detrend it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from scipy.signal import periodogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Load the data and plot it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px; width: 95%\">\n",
    "<p>\n",
    "<b>Task 1.1:</b>   \n",
    "\n",
    "Do the following:\n",
    "\n",
    "- load the data\n",
    "- create time vector\n",
    "- plot the data\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR_CODE_HERE\n",
    "\n",
    "data = YOUR_CODE_HERE # Temperature data\n",
    "time_days = YOUR_CODE_HERE # Time in days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px; width: 95%\">\n",
    "<p>\n",
    "<b>Task 1.2:</b>   \n",
    "\n",
    "Use the Markdown cell below to describe the data (you can use a few bullet points). For example, confirm relevant characteristics like number of points, units, describe the values (qualitatively), etc.\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Extract the Dominant Patterns\n",
    "\n",
    "We clearly see that the data contains a strong pattern (the general increase in temperature from winter to summer). We will start by fitting a functional model to the data in order to stationarize it. To find the frequency of the seasonal pattern we will use the power spectrum of the data.\n",
    "\n",
    "We will reuse the function `find_seasonal_pattern` from the workshop.\n",
    "\n",
    "Remember that for running this function we need to predefine the A-matrix to detrend the data. Since the data only contains the first 5 months of the year, we see that the temperature is increasing over time. What type of model would be most appropriate to remove the seasonal trend? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px; width: 95%\">\n",
    "<p>\n",
    "<b>Task 2.1:</b>   \n",
    "\n",
    "Define functions to help carry out this analysis, for example, <code>fit_model</code> and <code>find_frequency</code>.\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(data, time, A, plot=False):\n",
    "    '''\n",
    "    Function to find the least squares solution of the data\n",
    "    data: input data\n",
    "    time: time vector\n",
    "    A: A-matrix to fit the data\n",
    "    plot: boolean to plot the results or not\n",
    "    '''\n",
    "\n",
    "    x_hat = YOUR_CODE_HERE # least squares solution\n",
    "    y_hat = YOUR_CODE_HERE # model prediction\n",
    "    e_hat = YOUR_CODE_HERE # residuals\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(211)\n",
    "        plt.plot(time, data, label='Data')\n",
    "        plt.plot(time, y_hat, label='Estimated data')\n",
    "        plt.xlabel('Time [days]')\n",
    "        plt.ylabel('Temperature [°C]')\n",
    "        plt.title('Data vs Estimated data')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.subplot(212)\n",
    "        plt.plot(time, e_hat, label='Residuals')\n",
    "        plt.xlabel('Time [days]')\n",
    "        plt.ylabel('Temperature [°C]')\n",
    "        plt.title('Residuals')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "    return x_hat, y_hat, e_hat\n",
    "\n",
    "def find_frequency(data, time, A, fs, plot=True):\n",
    "    '''\n",
    "    Function to find the dominant frequency of the signal\n",
    "    data: input data\n",
    "    time: time vector\n",
    "    A: A-matrix to detrend the data (prior to spectral analysis)\n",
    "    fs: sampling frequency\n",
    "    plot: boolean to plot the psd or not\n",
    "    '''\n",
    "    # Detrending the data\n",
    "    _, _, e_hat= fit_model(YOUR_CODE_HERE)\n",
    "\n",
    "    N = len(data)\n",
    "\n",
    "    # Finding the dominant frequency in e_hat\n",
    "    freqs, pxx = periodogram(YOUR_CODE_HERE, fs=YOUR_CODE_HERE, window='boxcar',\n",
    "                                nfft=N, return_onesided=False,\n",
    "                                scaling='density')\n",
    "\n",
    "    # finding the dominant frequency and amplitude\n",
    "    # Note: there are many ways to do this\n",
    "    amplitude = YOUR_CODE_HERE # Amplitude of the dominant frequency\n",
    "    dominant_frequency = YOUR_CODE_HERE # Dominant frequency\n",
    "\n",
    "\n",
    "    # Plotting the PSD\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(211)\n",
    "        plt.plot(time, e_hat)\n",
    "        plt.title('Residuals')\n",
    "        plt.ylabel('Atmospheric Pressure [hPa]')\n",
    "        plt.grid(True)\n",
    "        plt.subplot(212)\n",
    "        plt.plot(freqs[freqs>0], pxx[freqs>0], label='PSD of residuals')\n",
    "        plt.xlabel('Frequency')\n",
    "        plt.ylabel('PSD')\n",
    "        plt.title('Power Spectral Density')\n",
    "        plt.grid(True)\n",
    "        plt.plot(dominant_frequency, amplitude, 'ro', label='Dominant Frequency')\n",
    "        plt.yscale('log')\n",
    "        plt.xscale('log')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "    return dominant_frequency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px; width: 95%\">\n",
    "<p>\n",
    "<b>Task 2.2:</b>   \n",
    "\n",
    "Now provide an A-matrix that removes the trend from the data. There are multiple answers that will work, but some are better than others.\n",
    "\n",
    "First, use the Markdown cell below to define your A-matrix and include a brief explanation justifying your choice.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px; width: 95%\">\n",
    "<p>\n",
    "<b>Task 2.3:</b>   \n",
    "\n",
    "Now define the A-matrix in code and extract the seasonal pattern. Continue extracting components until the time series is stationary (you will then summarize your findings in the next task).\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR_CODE_HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px; width: 95%\">\n",
    "<p>\n",
    "<b>Task 2.4:</b>   \n",
    "\n",
    "Describe how you have detrended the time series. Include at least: a) the number and types of components used (and their parameters; in task 2.5 you will print those), b) how you decided to stop extracting components.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Functional Model\n",
    "\n",
    "In the next cell we will fit the model to generate stationary residuals. Above, you may have a periodic signal, where for each dominant frequency $f_i$ ($i=1,2$) the model is:\n",
    "\n",
    "$$a_i  \\cos(2\\pi f_i  t) + b_i  \\sin(2\\pi f_i t)$$ \n",
    "\n",
    "However, to report the periodic signals we would like to have the amplitude, phase shift and the frequency of those signals, which can be recovered from:\n",
    "$$A_i  \\cos(2\\pi f_i  t + \\theta_i)$$\n",
    "Where the amplitude $A_i = \\sqrt{a_i^2 + b_i^2}$ and $\\theta_i = \\arctan(-b_i/a_i)$\n",
    "\n",
    "Note: in Section 4.1 book this was shown where the angular frequency $\\omega = 2\\pi f$ was used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px; width: 95%\">\n",
    "<p>\n",
    "<b>Task 2.5:</b>   \n",
    "\n",
    "Complete the code cell below to create the functional model.\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_seasonal_comp(ak, bk):\n",
    "    '''\n",
    "    Function to rewrite the seasonal component in terms of sin and cos\n",
    "    ak: seasonal component coefficient for cos\n",
    "    bk: seasonal component coefficient for sin\n",
    "\n",
    "    returns: Ak, theta_k\n",
    "    '''\n",
    "    YOUR_CODE_HERE\n",
    "\n",
    "# creating the A matrix of the functional model\n",
    "A = YOUR_CODE_HERE\n",
    "x_hat, y_hat, e_hat = YOUR_CODE_HERE\n",
    "\n",
    "# Plotting the data and the estimated trend\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(time_days, data, label='Original data')\n",
    "plt.plot(time_days, y_hat, label='Estimated trend')\n",
    "plt.xlabel('Time [days]')\n",
    "plt.ylabel('Temperature [°C]')\n",
    "plt.title('Temperature data Nenana, Alaska')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plotting the residuals\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(time_days, e_hat0)\n",
    "plt.xlabel('Time [days]')\n",
    "plt.ylabel('Temperature [°C]')\n",
    "plt.title('Residuals')\n",
    "plt.grid(True)\n",
    "\n",
    "# Extracting the seasonal component coefficients from the estimated parameters\n",
    "a_i = YOUR_CODE_HERE\n",
    "b_i = YOUR_CODE_HERE\n",
    "freqs = YOUR_CODE_HERE\n",
    "\n",
    "print(f'Estimated Parameters:')\n",
    "for i in range(len(x_hat)):\n",
    "    print(f'x{i} = {x_hat[i]:.3f}')\n",
    "\n",
    "print('\\nThe seasonal component is rewritten as:')\n",
    "i = 0\n",
    "for a, b, f in zip(a_i, b_i, freqs):\n",
    "    A_i, theta_i = rewrite_seasonal_comp(a, b)\n",
    "    i += 1\n",
    "    print(f'A_{i} = {A_i:.3f}, theta_{i} = {theta_i:.3f}, f_{i} = {f:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px; width: 95%\">\n",
    "<p>\n",
    "<b>Task 2.6:</b>   \n",
    "\n",
    "Are the residuals stationary? State yes or no and describe why in the cell below.\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Finding the grizzly\n",
    "\n",
    "When we look at the residuals after removing the periodic pattern(s), we see that there is still a pattern in the data. From researchers in the Nenana area we have heard that there is a grizzly bear that likes to take a nap (hibernate) in the area. We suspect that the grizzly bear has slept too close to the temperature sensor and has influenced the data. \n",
    "\n",
    "In the next cell we will write an offset detection algorithm to find the offset in the data. The offset detection algorithm is based on the likelihood ratio test framework. However, due to the presence of autocorrelation in the residuals, the traditional critical values for the likelihood ratio test are not valid. Therefore, we will use a bootstrap approach to estimate the critical values. Luckily, this is **not** the first time we had to remove a grizzly bear from our data, so we know that the estimated critical values is approximately 100 (i.e. you do not have to find this value yourself!).\n",
    "\n",
    "## The offset detection algorithm\n",
    "The offset detection algorithm is based on the likelihood ratio test framework. The likelihood ratio test has a test statistic that is given by:\n",
    "\n",
    "$$\\Lambda = n \\log \\left( \\frac{SSR_0}{SSR_1} \\right)$$\n",
    "\n",
    "$$SSR_i = \\sum_{i=1}^n (\\hat{e}_i)^2$$\n",
    "\n",
    "where $SSR_0$ is the sum of the squared residuals for the model without an offset, $SSR_1$ is the sum of the squared residuals for the model with an offset, and $n$ is the number of data points. The likelihood ratio test statistic is compared to a critical value to determine if an offset is present in the data.\n",
    "\n",
    "The cell below defines several functions which roughly accomplish the following:\n",
    " \n",
    "1. Calculate the sum of the squared residuals for the model without an offset, $SSR_0$.\n",
    "2. Calculate the sum of the squared residuals for the model with an offset at each possible point, $SSR_1$.\n",
    "   1. For each possible offset location, we will calculate the sum of the squared residuals for the model with an offset at that data point.\n",
    "   2. The A-matrix for the model with an offset is the same as the A-matrix for the model without an offset, but with an additional column that is 0 till the data point and 1 after the data point.\n",
    "3. At each possible offset location, calculate the likelihood ratio test statistic and store it in the `results` vector.\n",
    "4. We will find the offset location that maximizes the likelihood ratio test statistic, i.e. the location where an offset is *most* likely.\n",
    "5. We will include the offset in the model and repeat the process until the likelihood ratio test statistic is below the critical value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px; width: 95%\">\n",
    "<p>\n",
    "<b>Task 3.1:</b>   \n",
    "\n",
    "Using the description above and the comments and docstring in the code, fill in the code below to complete the offset detection algorithm.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A1_matrix(A0, break_point):\n",
    "    '''\n",
    "    Function to create the A1 matrix\n",
    "    A0: A matrix under H0\n",
    "    break_point: break point location\n",
    "    return: A1 matrix\n",
    "    '''\n",
    "    # create the new column and stack it to the A0 matrix\n",
    "    YOUR_CODE_HERE\n",
    "    \n",
    "    return YOUR_CODE_HERE\n",
    "\n",
    "\n",
    "def LR(e0, e1, cv=100, verbose=True):\n",
    "    '''\n",
    "    Function to perform the LR test\n",
    "    e0: residuals under H0\n",
    "    e1: residuals under H1\n",
    "    cv: critical value\n",
    "    '''\n",
    "    n = YOUR_CODE_HERE\n",
    "    SSR0 = YOUR_CODE_HERE\n",
    "    SSR1 = YOUR_CODE_HERE\n",
    "    test_stat = YOUR_CODE_HERE\n",
    "    \n",
    "    if test_stat > cv:\n",
    "        if verbose:\n",
    "            print(f'Test Statistic: {test_stat:.3f} > Critical Value: {cv:.3f}')\n",
    "            print('Reject the null hypothesis')\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(f'Test Statistic: {test_stat:.3f} < Critical Value: {cv:.3f}')\n",
    "            print('Fail to reject the null hypothesis')\n",
    "    return test_stat\n",
    "\n",
    "def jump_detection(data, time, A, cv=100, plot=True):\n",
    "    '''\n",
    "    Function to detect the jump in the data\n",
    "    data: input data\n",
    "    time: time vector\n",
    "    A: A matrix under H0\n",
    "    cv: critical value\n",
    "    plot: boolean to plot the results or not\n",
    "    '''\n",
    "    # initialize the results vector\n",
    "    results = YOUR_CODE_HERE\n",
    "    # find the residuals under H0\n",
    "    YOUR_CODE_HERE\n",
    "\n",
    "    # loop over the data points\n",
    "    for i in range(1, len(data)):\n",
    "        # create the A1 matrix\n",
    "        A1 = YOUR_CODE_HERE\n",
    "\n",
    "        # We need this statement to avoid singular matrices\n",
    "        if np.linalg.matrix_rank(A1) < A1.shape[1]:\n",
    "            pass\n",
    "        else:\n",
    "            # find the residuals under H1\n",
    "            _, _, e_hat1 = YOUR_CODE_HERE\n",
    "            test_stat = YOUR_CODE_HERE\n",
    "            results[i] = YOUR_CODE_HERE\n",
    "\n",
    "    results = np.array(results)\n",
    "    \n",
    "    # finding the offset location. \n",
    "    # Offset is the location where the test statistic is maximum\n",
    "    location = YOUR_CODE_HERE\n",
    "    value = YOUR_CODE_HERE\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 3))\n",
    "        plt.plot(time, results)\n",
    "        plt.plot(time[location], value, 'ro', label='offset')\n",
    "        plt.plot([0, max(time)], [cv, cv], 'k--', label='Critical Value')\n",
    "        plt.xlabel('Time [days]')\n",
    "        plt.ylabel('Test Statistic')\n",
    "        plt.title('LR Test')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "\n",
    "    return location, value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px; width: 95%\">\n",
    "<p>\n",
    "<b>Task 3.2:</b>   \n",
    "\n",
    "Before we implement the offset detection algorithm use the following Markdown cell to describe the following in a few sentences or bullet points:\n",
    "\n",
    "How is this process similar to the one we used to find a periodic pattern? How is it different?\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px; width: 95%\">\n",
    "<p>\n",
    "<b>Task 3.3:</b>   \n",
    "\n",
    "Now we will implement the offset detection algorithm by using the functions defined above to find the offset in the data. The function will provide figures from which you will be able to determine the offset.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR_CODE_HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px; width: 95%\">\n",
    "<p>\n",
    "<b>Task 3.4:</b>   \n",
    "\n",
    "Write your chosen offset in the cell below (report both the size and location of the offset). \n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My offset is: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px; width: 95%\">\n",
    "<p>\n",
    "<b>Task 3.5:</b>   \n",
    "\n",
    "Once you have found the offset, identify the offset location and update your A-matrix to include it in the model. Then repeat the process until the likelihood ratio test statistic is below the critical value.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2 = YOUR_CODE_HERE\n",
    "x_hat, y_hat, e_hat = fit_model(YOUR_CODE_HERE)\n",
    "\n",
    "# Plotting the data and the estimated trend\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(time_days, data, label='Original data')\n",
    "plt.plot(time_days, y_hat, label='Estimated trend')\n",
    "plt.xlabel('Time [days]')\n",
    "plt.ylabel('Temperature [°C]')\n",
    "plt.title('Temperature data Nenana, Alaska')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plotting the residuals\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(time_days, e_hat)\n",
    "plt.xlabel('Time [days]')\n",
    "plt.ylabel('Temperature [°C]')\n",
    "plt.title('Residuals')\n",
    "plt.grid(True)\n",
    "\n",
    "# Extracting the seasonal component coefficients from the estimated parameters\n",
    "a_i = YOUR_CODE_HERE\n",
    "b_i = YOUR_CODE_HERE\n",
    "freqs = YOUR_CODE_HERE\n",
    "\n",
    "print(f'Estimated Parameters:')\n",
    "for i in range(len(x_hat)):\n",
    "    print(f'x{i} = {x_hat[i]:.3f}')\n",
    "\n",
    "print('\\nThe seasonal component is rewritten as:')\n",
    "i = 0\n",
    "for a, b, f in zip(a_i, b_i, freqs):\n",
    "    A_i, theta_i = rewrite_seasonal_comp(a, b)\n",
    "    i += 1\n",
    "    print(f'A_{i} = {A_i:.3f}, theta_{i} = {theta_i:.3f}, f_{i} = {f:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px; width: 95%\">\n",
    "<p>\n",
    "<b>Task 3.6:</b>   \n",
    "\n",
    "Use the Markdown cell below to summarize the location and size of the offset(s) you have found. Include the number of components used in the final model.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Analyzing the residuals\n",
    "Now that we have our residuals we can fit an AR model to the residuals. We will start by plotting the ACF of the residuals. We will then fit an AR model to the residuals and report the parameters of the AR model. Using the likelihood ratio test framework we will determine the order of the AR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets start with the ACF plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 3))\n",
    "plot_acf(e_hat, ax=ax, lags=20);\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px; width: 95%\">\n",
    "<p>\n",
    "<b>Task 4.1:</b>   \n",
    "\n",
    "Begin by completing the functions below to define AR(1) (hint: you did this on Wednesday).\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AR1(s, time, plot=True):\n",
    "    '''\n",
    "    Function to find the AR(1) model of the given data\n",
    "    s: input data\n",
    "    return: x_hat, e_hat\n",
    "    '''\n",
    "    y = YOUR_CODE_HERE\n",
    "    y_lag_1 = YOUR_CODE_HERE\n",
    "    A = np.atleast_2d(y_lag_1).T\n",
    "    x_hat, y_hat, e_hat = fit_model(YOUR_CODE_HERE)\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(2, 1, figsize=(10, 5))\n",
    "        ax[0].plot(time[1:], y, label='Original Residuals')\n",
    "        ax[0].plot(time[1:], y_hat, label='Estimated Residuals')\n",
    "        ax[0].set_xlabel('Time [days]')\n",
    "        ax[0].set_ylabel('Temperature [°C]')\n",
    "        ax[0].set_title('Original Data vs Estimated Data')\n",
    "        ax[0].grid(True)\n",
    "        ax[0].legend()\n",
    "        plot_acf(e_hat, ax=ax[1], lags=20)\n",
    "        ax[1].grid()\n",
    "        fig.tight_layout()\n",
    "        \n",
    "    print(f'Estimated Parameters:')\n",
    "    print(f'phi = {x_hat[0]:.4f}')\n",
    "\n",
    "    return x_hat, e_hat\n",
    "\n",
    "# Estimating the AR(1) model\n",
    "phi_hat_ar1, e_hat_ar1 = AR1(YOUR_CODE_HERE)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px; width: 95%\">\n",
    "<p>\n",
    "<b>Task 4.2:</b>   \n",
    "\n",
    "- As you can see, the next task asks you to implement AR(2). State why this is necessary, using the results from the cell above.\n",
    "- Based on the ACF plot, will the $\\phi_2$ parameter in the AR(2) be positive or negative? Why? \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px; width: 95%\">\n",
    "<p>\n",
    "<b>Task 4.3:</b>   \n",
    "\n",
    "Now complete the functions to set up AR(2).\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AR2(s, time, plot=True):\n",
    "    '''\n",
    "    Function to find the AR(2) model of the given data\n",
    "    s: input data\n",
    "    return: x_hat, e_hat\n",
    "    '''\n",
    "    y = YOUR_CODE_HERE\n",
    "    y_lag_1 = YOUR_CODE_HERE\n",
    "    y_lag_2 = YOUR_CODE_HERE\n",
    "    A = YOUR_CODE_HERE\n",
    "    x_hat, y_hat, e_hat = fit_model(YOUR_CODE_HERE)\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(2, 1, figsize=(10, 5))\n",
    "        ax[0].plot(time[2:], y, label='Original Residuals')\n",
    "        ax[0].plot(time[2:], y_hat, label='Estimated Residuals')\n",
    "        ax[0].set_xlabel('Time [days]')\n",
    "        ax[0].set_ylabel('Temperature [°C]')\n",
    "        ax[0].set_title('Original Data vs Estimated Data')\n",
    "        ax[0].grid(True)\n",
    "        ax[0].legend()\n",
    "        plot_acf(e_hat, ax=ax[1], lags=20)\n",
    "        ax[1].grid()\n",
    "        fig.tight_layout()\n",
    "\n",
    "    print(f'Estimated Parameters:')\n",
    "    print(f'phi_1 = {x_hat[0]:.4f}, phi_2 = {x_hat[1]:.4f}')\n",
    "\n",
    "    return x_hat, e_hat\n",
    "\n",
    "# Estimating the AR(2) model\n",
    "phi_hat_ar2, e_hat_ar2 = AR2(YOUR_CODE_HERE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Report the Results\n",
    "\n",
    "_Note: you did this on Wednesday! It was optional then, so you are not expected to know this for the exam; however, you should implement the code using the WS as a template, and your interpretation at the end will be part of the grade for this assignment._\n",
    "\n",
    "Now that we have found the periodic signals in the data and fitted an AR model to the residuals, we can report the results. By combining including the AR (noise) process, we get residuals that are white noise. When the model has white noise residuals, we can also report the confidence intervals of the model. The estimated variance is only consistent when the residuals are white noise.\n",
    "\n",
    "We will use the unbiased estimate of the variance of the residuals to calculate the confidence intervals. The unbiased estimate of the variance is given by:\n",
    "\n",
    "$$\\hat{\\sigma}^2 = \\frac{1}{n-p} \\sum_{t=1}^{n} \\hat{e}_t^2$$\n",
    "\n",
    "Where $n$ is the number of observations and $p$ is the number of parameters in the model.\n",
    "\n",
    "The covariance matrix of the parameters is given by:\n",
    "\n",
    "$$\\hat{\\Sigma} = \\hat{\\sigma}^2 (\\mathbf{A}^T \\mathbf{A})^{-1}$$\n",
    "\n",
    "Where $\\mathbf{A}$ is the design matrix of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px; width: 95%\"> <p> <b>Task 4.1:</b>   \n",
    "<p>\n",
    "Complete the missing parts of the code cell below. Note that you will need to add one additional term, compared to Wednesday.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine ar2 and functional model\n",
    "A_final = YOUR_CODE_HERE\n",
    "x_hat, y_hat, e_hat_final = fit_model(YOUR_CODE_HERE)\n",
    "\n",
    "# Plotting the acf of the residuals\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 3))\n",
    "plot_acf(YOUR_CODE_HERE, ax=ax, lags=20);\n",
    "ax.grid()\n",
    "\n",
    "# compute the standard errors\n",
    "N = YOUR_CODE_HERE\n",
    "p = YOUR_CODE_HERE\n",
    "sigma2 = YOUR_CODE_HERE\n",
    "Cov = YOUR_CODE_HERE\n",
    "se = YOUR_CODE_HERE\n",
    "\n",
    "# Extracting the seasonal component coefficients from the estimated parameters\n",
    "a_i = YOUR_CODE_HERE\n",
    "b_i = YOUR_CODE_HERE\n",
    "freqs = YOUR_CODE_HERE\n",
    "\n",
    "# Check if the number of coefficients match the number of frequencies\n",
    "assert len(a_i) == len(b_i) == len(freqs), 'The number of coefficients do not match'\n",
    "\n",
    "print(f'Estimated Parameters (standard deviation):')\n",
    "for i in range(len(x_hat)):\n",
    "    print(f'x{i} = {x_hat[i]:.3f}\\t\\t ({se[i]:.3f})')\n",
    "\n",
    "print('\\nThe seasonal component is rewritten as:')\n",
    "i = 0\n",
    "for a, b, f in zip(a_i, b_i, freqs):\n",
    "    A_i, theta_i = rewrite_seasonal_comp(a, b)\n",
    "    i += 1\n",
    "    print(f'A_{i} = {A_i:.3f}, theta_{i} = {theta_i:.3f}, f_{i} = {f:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px; width: 95%\">\n",
    "<p>\n",
    "<b>Task 4.2:</b>   \n",
    "\n",
    "Now we have the complete functional model. Reflect on it's suitability for capturing the time dependent variation of temperature throughout the spring. Comment specifically on the time series components that were included and which ones have the most significant influence on the result.\n",
    "\n",
    "Compare your final parameters to the ones you found in the previous tasks (i.e. model without offset, model with offset). Are they similar? If not, why do you think that is?\n",
    "\n",
    "Comment also on the suitability of this model for predicting the temperature **beyond the betting deadline of April 5**, assuming that you have data up **until** that date. Remember that the ice typically breaks apart 2 to 6 weeks after the betting deadline.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End of notebook.**\n",
    "<h2 style=\"height: 60px\">\n",
    "</h2>\n",
    "<h3 style=\"position: absolute; display: flex; flex-grow: 0; flex-shrink: 0; flex-direction: row-reverse; bottom: 60px; right: 50px; margin: 0; border: 0\">\n",
    "    <style>\n",
    "        .markdown {width:100%; position: relative}\n",
    "        article { position: relative }\n",
    "    </style>\n",
    "    <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">\n",
    "      <img alt=\"Creative Commons License\" style=\"border-width:; width:88px; height:auto; padding-top:10px\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" />\n",
    "    </a>\n",
    "    <a rel=\"TU Delft\" href=\"https://www.tudelft.nl/en/ceg\">\n",
    "      <img alt=\"TU Delft\" style=\"border-width:0; width:100px; height:auto; padding-bottom:0px\" src=\"https://gitlab.tudelft.nl/mude/public/-/raw/main/tu-logo/TU_P1_full-color.png\" />\n",
    "    </a>\n",
    "    <a rel=\"MUDE\" href=\"http://mude.citg.tudelft.nl/\">\n",
    "      <img alt=\"MUDE\" style=\"border-width:0; width:100px; height:auto; padding-bottom:0px\" src=\"https://gitlab.tudelft.nl/mude/public/-/raw/main/mude-logo/MUDE_Logo-small.png\" />\n",
    "    </a>\n",
    "    \n",
    "</h3>\n",
    "<span style=\"font-size: 75%\">\n",
    "&copy; Copyright 2024 <a rel=\"MUDE\" href=\"http://mude.citg.tudelft.nl/\">MUDE</a> TU Delft. This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">CC BY 4.0 License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mude-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
